{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import zipfile\n",
    "import os\n",
    "import decimal as d\n",
    "import numpy as np\n",
    "import json\n",
    "import unet\n",
    "import image_processor\n",
    "import torchvision\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "import pickle\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelLoader(model, path: str):\n",
    "    return model.load_state_dict(torch.load(path))\n",
    "\n",
    "#thanks, Chat GPT\n",
    "def unzip_file(zip_file_path, extract_to_path):\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to_path)\n",
    "\n",
    "#thanks, Chat GPT\n",
    "def sortFirstNFiles(directoryPath: str, n: int = 10):\n",
    "    allFiles = [os.path.join(directoryPath, file) for file in os.listdir(directoryPath) if file.endswith(('pt', '.pt'))]\n",
    "    #sorts filenames based on third segment (validationloss in name)\n",
    "    sortedFiles = sorted(allFiles, key = lambda fileName: int(fileName.split(os.sep)[-1].split('_')[2]))\n",
    "\n",
    "    firstFiles = sortedFiles[:n]\n",
    "\n",
    "    return firstFiles\n",
    "\n",
    "def mapImageTensor(tensor: torch.Tensor, center = 0, scale = 1):\n",
    "    return 1/ (1 + torch.exp(-(tensor - center)/scale))\n",
    "\n",
    "def highPrecisionArray(numOfSamples, beg=0, last=1, precision = 4):\n",
    "    d.getcontext().prec = precision\n",
    "    start = d.Decimal(beg)\n",
    "    end = d.Decimal(last)\n",
    "    step = (end - start) / d.Decimal(numOfSamples - 1)\n",
    "    numArray = [start + i * step for i in range(numOfSamples)]\n",
    "    numArray = [float(x) for x in numArray]\n",
    "    return numArray\n",
    "\n",
    "def metrics(pred, label):\n",
    "    if torch.is_tensor(pred) or torch.is_tensor(label):\n",
    "        pred = pred.detach().cpu().numpy()\n",
    "        label = label.detach().cpu().numpy()\n",
    "    \n",
    "    TP = ((label == 255) & (pred == 255)).sum()\n",
    "    FP = ((label == 0) & (pred == 255)).sum()\n",
    "    TN = ((label == 0) & (pred == 0)).sum()\n",
    "    FN = ((label == 255) & (pred == 0)).sum()\n",
    "\n",
    "    return int(TP), int(FP), int(TN), int(FN)\n",
    "\n",
    "def dice(TP, FP, FN):\n",
    "    if (2*TP + FP + FN) == 0:\n",
    "        return 0\n",
    "    return round(2*TP / ( 2*TP + FP + FN), 3)\n",
    "\n",
    "#thanks, Chat GPT\n",
    "def rectTriArea(x_values, y_values):\n",
    "    n = len(x_values)\n",
    "    area = 0.0\n",
    "    for i in range(1, n):\n",
    "        width = x_values[i] - x_values[i - 1]\n",
    "        height = min(y_values[i - 1], y_values[i])\n",
    "        rectArea = width*height\n",
    "\n",
    "        deltaHeight = max(y_values[i], y_values[i-1]) - height\n",
    "\n",
    "        triArea = .5 * deltaHeight*width\n",
    "        area += rectArea + triArea\n",
    "    return area\n",
    "\n",
    "def framePlotter(pred , label, frameNum: int, caseNum: int, modelName: str, saveDir: str):\n",
    "    if torch.is_tensor(pred) or torch.is_tensor(label):\n",
    "        pred = pred.detach().cpu().numpy()\n",
    "        label = label.detach().cpu().numpy()\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.imshow(pred.transpose(1,2,0))\n",
    "    #parts = modelName.split(\"\\\\\")\n",
    "    #modelName = parts[3]\n",
    "    plt.title(f'Pred- {modelName} | C: {caseNum} F: {frameNum}')\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.imshow(label.transpose(1,2,0))\n",
    "    plt.title(f'Label- {modelName} | C: {caseNum} F: {frameNum}')\n",
    "    savePath = os.path.join(saveDir, modelName + '_C_' + str(caseNum) + '_F_' + str(frameNum) + '.png')\n",
    "    plt.savefig(savePath)\n",
    "    plt.show()\n",
    "\n",
    "def findLogModels(logModelDir, modelName):\n",
    "    matches = []\n",
    "    for root, dirnames, filenames in os.walk(logModelDir):\n",
    "        for filename in filenames:\n",
    "            if fnmatch.fnmatch(filename, f'*{modelName}*'):\n",
    "                matches.append(os.path.join(root, filename))\n",
    "    return matches\n",
    "\n",
    "def sigmoidalCurve(x, a, s, c):\n",
    "    return a / (1 + np.exp(-s * (x - c)))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START: C:\\Users\\myfir\\My Drive\\Segmentation_Files\\Models\\Test\\unet\\unet16x_VL_98_CE_144_TE_400_LR_0.001_BS_16_TS_2024-04-12_22-46-01.pt | 2024-05-09 21:04:44\n",
      "Starting Log Model Loader\n",
      "START: Threshold Search | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.0 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.033333 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.066666 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.099999 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.13333 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.16666 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.2 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.23333 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.26666 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.3 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.33333 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.36666 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.4 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.43333 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.46666 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.5 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.53333 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.56666 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.59999 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.63333 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.66666 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.69999 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.73333 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.76666 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.79999 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.83332 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.86666 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.89999 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.93332 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.96666 | 2024-05-09 21:05:43\n",
      "START: Threshold: 0.99999 | 2024-05-09 21:05:43\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "sigmoid val tensors\n",
    "flatten val tensors\n",
    "add flattened val tensors to array\n",
    "flatten and add to list labels\n",
    "polytransform array to Z dimension\n",
    "logistic regresson on Z, list labels\n",
    "apply model to predict result of sig-flat test images\n",
    "construct prediction label from output list\n",
    "compare pred label to label\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "size of Z dim = (n+(d-1))Cd \n",
    "(n+(d-1)) Choose d degrees\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Take val data\n",
    "Fit curve to val data\n",
    "find threshold through search\n",
    "take fit curve and threshold and apply to test set\n",
    "compare\n",
    "\"\"\"\n",
    "\n",
    "degree = 2\n",
    "downscale = 16\n",
    "testCases = 4\n",
    "imagesPerTestCase = 100\n",
    "numOfModelsToTest = 1\n",
    "height = int(256/downscale)\n",
    "width = int(1024/downscale)\n",
    "shape = (height, width)\n",
    "\n",
    "logModelDir = r\"C:\\Users\\myfir\\My Drive\\Segmentation_Files\\Performance_Results\\5-9\\LogModelAndGraphs\"\n",
    "modelDirectory = r\"C:\\Users\\myfir\\My Drive\\Segmentation_Files\\Models\\Test\\unet\"\n",
    "\n",
    "thresholds = highPrecisionArray(31, 0, 1, 5)\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((height, width))])\n",
    "\n",
    "\n",
    "logModelImagePath = r\"C:\\Users\\myfir\\My Drive\\Segmentation_Files\\Datasets\\Rename_Data\\train_val\\Rename_TrainVal_Image\"\n",
    "logModelLabelPath = r\"C:\\Users\\myfir\\My Drive\\Segmentation_Files\\Datasets\\Rename_Data\\train_val\\Rename_TrainVal_Label\"\n",
    "segmentationPath = f\"{logModelDir}\\Segmentations\"\n",
    "\n",
    "if not os.path.exists(segmentationPath):\n",
    "    os.makedirs(segmentationPath)\n",
    "\n",
    "testImagePath = r\"C:\\Users\\myfir\\My Drive\\Segmentation_Files\\Datasets\\Rename_Data\\test\\Rename_Test_Image\"\n",
    "testLabelPath = r\"C:\\Users\\myfir\\My Drive\\Segmentation_Files\\Datasets\\Rename_Data\\test\\Rename_Test_Label\"\n",
    "\n",
    "topModelPaths = sortFirstNFiles(modelDirectory, numOfModelsToTest)\n",
    "\n",
    "logModelFitLoader= image_processor.imageDirsToTestLoader(imageDir=logModelImagePath, labelDir= logModelLabelPath, transform=transform)\n",
    "testLoader = image_processor.imageDirsToTestLoader(imageDir=testImagePath, labelDir=testLabelPath, transform=transform)\n",
    "\n",
    "for modelPath in topModelPaths:\n",
    "    currentTime = datetime.now()\n",
    "    formatTime = currentTime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f'START: {modelPath} | {formatTime}')\n",
    "    print(f'Starting Log Model Loader')\n",
    "    model = unet.unet()\n",
    "    model.loadAttributes(modelPath)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    listOfFlattenedOutputs = []\n",
    "    listOfLabels = []\n",
    "\n",
    "    for i, (image, label) in enumerate(logModelFitLoader):\n",
    "        #with batch size of 1, i ranges from 0-399 in test set of 400 images\n",
    "        #0-879 for training set\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        output = model(image)\n",
    "        #output = mapImageTensor(output)\n",
    "        outputArray = output.detach().cpu().numpy().reshape(-1)\n",
    "        labelArray = label.detach().cpu().numpy().reshape(-1)\n",
    "\n",
    "        listOfFlattenedOutputs.append(outputArray)\n",
    "        listOfLabels.append(labelArray)\n",
    "    \n",
    "    arrayOfFlattenedOutputs = np.array(listOfFlattenedOutputs).reshape(-1,1)\n",
    "    poly = PolynomialFeatures(degree = degree)\n",
    "    #each column in input is a \n",
    "    #880, 525825\n",
    "    #transformedArrayOfFlattenedOutputs = poly.fit_transform(arrayOfFlattenedOutputs)\n",
    "    #880, 1024\n",
    "    arrayOfLabels = np.array(listOfLabels).reshape(-1)\n",
    "\n",
    "    logModel = LogisticRegression().fit(arrayOfFlattenedOutputs, arrayOfLabels)\n",
    "\n",
    "    probabilities = logModel.predict_proba(arrayOfFlattenedOutputs)\n",
    "\n",
    "    bestScore = 0\n",
    "    bestThreshold = 0\n",
    "\n",
    "    currentTime = datetime.now()\n",
    "    formatTime = currentTime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f'START: Threshold Search | {formatTime}')\n",
    "\n",
    "    for i, t in enumerate(thresholds):\n",
    "        currentTime = datetime.now()\n",
    "        formatTime = currentTime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(f'START: Threshold: {t} | {formatTime}')\n",
    "        yPred = (probabilities[:, 1] > t).astype(int)\n",
    "        yPredArray = np.array(yPred)\n",
    "        yPredArray[yPredArray > .9] = 255\n",
    "        TP, FP, TN, FN = metrics(yPredArray, arrayOfLabels)\n",
    "        score = dice(TP, FP, FN)\n",
    "        if score > bestScore:\n",
    "            bestScore = score\n",
    "            bestThreshold = t\n",
    "    \n",
    "    logModelName = f'logModel_{model.name}_degree_{degree}_dice_{bestScore}_t_{bestThreshold}'\n",
    "    logModelPath = os.path.join(logModelDir, f'{logModelName}.pkl')\n",
    "\n",
    "    with open(logModelPath, 'wb') as file:\n",
    "        pickle.dump(logModel, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START: C:\\Users\\myfir\\My Drive\\Segmentation_Files\\Models\\Test\\unet\\unet16x_VL_98_CE_144_TE_400_LR_0.001_BS_16_TS_2024-04-12_22-46-01.pt | 2024-05-09 21:21:39\n",
      "Starting Log Model Loader\n",
      "Analyzing unet16x_VL_98_CE_144_TE_400_LR_0.001_BS_16_TS_2024-04-12_22-46-01 on Log Model C:\\Users\\myfir\\My Drive\\Segmentation_Files\\Performance_Results\\5-9\\LogModelAndGraphs\\logModel_unet16x_VL_98_CE_144_TE_400_LR_0.001_BS_16_TS_2024-04-12_22-46-01_degree_2_dice_0.976_t_0.066666.pkl\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m         caseNum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     56\u001b[0m     diceByFrame[frameNum] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m score\n\u001b[1;32m---> 57\u001b[0m     \u001b[43mframePlotter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myPredArray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabelArray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframeNum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframeNum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaseNum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaseNum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaveDir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msegmentationPath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m diceByFrame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m.25\u001b[39m, diceByFrame))\n\u001b[0;32m     63\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(diceByFrame)\n",
      "Cell \u001b[1;32mIn[6], line 68\u001b[0m, in \u001b[0;36mframePlotter\u001b[1;34m(pred, label, frameNum, caseNum, modelName, saveDir)\u001b[0m\n\u001b[0;32m     66\u001b[0m     label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     67\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m#parts = modelName.split(\"\\\\\")\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m#modelName = parts[3]\u001b[39;00m\n\u001b[0;32m     71\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPred- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodelName\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | C: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaseNum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m F: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframeNum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: axes don't match array"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "for modelPath in topModelPaths:\n",
    "    currentTime = datetime.now()\n",
    "    formatTime = currentTime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f'START: {modelPath} | {formatTime}')\n",
    "    print(f'Starting Log Model Loader')\n",
    "    model = unet.unet()\n",
    "    model.loadAttributes(modelPath)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    poly = PolynomialFeatures(degree = degree)\n",
    "    matches = findLogModels(logModelDir, model.name)\n",
    "\n",
    "    for match in matches:\n",
    "        print(f'Analyzing {model.name} on Log Model {match}')\n",
    "        with open(match, 'rb') as file:\n",
    "            logModel = pickle.load(file)\n",
    "        parts = match.split('_')\n",
    "        parts = parts[-1].split('.pkl')\n",
    "        t = float(parts[0])\n",
    "        diceByFrame = [0]*100\n",
    "        caseNum = 0\n",
    "        \n",
    "        #done with a batch size of one to not stress equipment\n",
    "        for i, (image, label) in enumerate(testLoader):\n",
    "            #with batch size of 1, i ranges from 0-399 in test set of 400 images\n",
    "            #0-779 for training set\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(image)\n",
    "            #output = mapImageTensor(output)\n",
    "            #(1024,)\n",
    "            outputArray = output.detach().cpu().numpy().reshape(-1,1)\n",
    "            #(256/downscale, 1024/downscale)\n",
    "            labelArray = label.detach().cpu().numpy().reshape(shape)\n",
    "\n",
    "            #arrayOfFlattenedOutputs = np.array(listOfFlattenedOutputs).reshape(-1,1)\n",
    "            #arrayOfLabels = np.array(listOfLabels).reshape(-1)\n",
    "            #transformedArrayOfFlattenedOutputs = poly.fit_transform(outputArray)\n",
    "            probabilities = logModel.predict_proba(outputArray)\n",
    "            yPred = (probabilities[:, 1] > t).astype(int)\n",
    "            yPredArray = np.array(yPred).reshape(shape)\n",
    "\n",
    "\n",
    "            TP, FP, TN, FN = metrics(yPredArray, labelArray)\n",
    "            score = dice(TP, FP, FN)\n",
    "\n",
    "            #reshaping flattened array to graph predictions\n",
    "            yPredArray.reshape(shape)\n",
    "            labelArray.reshape(shape)\n",
    "\n",
    "            frameNum = i%100\n",
    "            if frameNum == 0:\n",
    "                caseNum += 1\n",
    "\n",
    "            diceByFrame[frameNum] += score\n",
    "            framePlotter(pred=yPredArray, label=labelArray, frameNum=frameNum, caseNum=caseNum, modelName= match, saveDir=segmentationPath)\n",
    "\n",
    "            \n",
    "\n",
    "        diceByFrame = list(map(lambda x: x * .25, diceByFrame))\n",
    "\n",
    "        plt.plot(diceByFrame)\n",
    "        plt.title(f\"Avg. Dice by Frame for {match}\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m testImagePath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m testLabelPath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 13\u001b[0m topModelPaths \u001b[38;5;241m=\u001b[39m \u001b[43msortFirstNFiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelDirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m logModelFitLoader\u001b[38;5;241m=\u001b[39m image_processor\u001b[38;5;241m.\u001b[39mimageDirsToTestLoader(imageDir\u001b[38;5;241m=\u001b[39mtestImagePath, labelDir\u001b[38;5;241m=\u001b[39m testLabelPath)\n\u001b[0;32m     16\u001b[0m allDiceResults \u001b[38;5;241m=\u001b[39m {path : {} \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m topModelPaths}\n",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m, in \u001b[0;36msortFirstNFiles\u001b[1;34m(directoryPath, n)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msortFirstNFiles\u001b[39m(directoryPath: \u001b[38;5;28mstr\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m---> 11\u001b[0m     allFiles \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directoryPath, file) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectoryPath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))]\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m#sorts filenames based on third segment (validationloss in name)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     sortedFiles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(allFiles, key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m fileName: \u001b[38;5;28mint\u001b[39m(fileName\u001b[38;5;241m.\u001b[39msplit(os\u001b[38;5;241m.\u001b[39msep)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m2\u001b[39m]))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: ''"
     ]
    }
   ],
   "source": [
    "modelDirectory = r\"\"\n",
    "thresholds = highPrecisionArray(20, 0, 1, 5)\n",
    "scales = highPrecisionArray(20, 1 , 500)\n",
    "centers = highPrecisionArray(25, 0, 255)\n",
    "scaleCentersProduct = list(itertools.product(scales, centers))\n",
    "\n",
    "#downscale = torchvision.transforms.Compose([\n",
    "#    torchvision.transforms.Resize((16, 64))])\n",
    "\n",
    "testImagePath = r\"\"\n",
    "testLabelPath = r\"\"\n",
    "\n",
    "topModelPaths = sortFirstNFiles(modelDirectory, 1)\n",
    "logModelFitLoader= image_processor.imageDirsToTestLoader(imageDir=testImagePath, labelDir= testLabelPath)\n",
    "\n",
    "allDiceResults = {path : {} for path in topModelPaths}\n",
    "allMetricResults = {path : {} for path in topModelPaths}\n",
    "#allFrameResults = {path : {} for path in topModelPaths}\n",
    "\n",
    "for modelPath in topModelPaths:\n",
    "    currentTime = datetime.now()\n",
    "    formatTime = currentTime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f'START: {modelPath} | {formatTime}')\n",
    "    model = unet.unet()\n",
    "    model.load_state_dict(torch.load(modelPath))\n",
    "    #model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "\n",
    "    diceResultsByScaleCenter = {f'{s}, {c}': {} for s, c in scaleCentersProduct}\n",
    "    metricResultsByScaleCenter = {f'{s}, {c}': {} for s, c in scaleCentersProduct}\n",
    "    #predLabelResultsByScaleCenter = {f'{s}, {c}': {} for s, c in scaleCentersProduct}\n",
    "\n",
    "    for s, c in scaleCentersProduct:\n",
    "        currentTime = datetime.now()\n",
    "        formatTime = currentTime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(f'SCALE: {s} - CENTER: {c} | {formatTime}')\n",
    "\n",
    "        diceByThreshold = {str(t): [0]*100 for t in thresholds}\n",
    "        metricsByThreshold = {str(t): [[0, 0, 0, 0]]*100 for t in thresholds}\n",
    "        #caseByThreshold = {str(t): {str(i+1): [] for i in range(len(testLoader))} for t in thresholds}\n",
    "\n",
    "        for i, (image, label) in enumerate(logModelFitLoader): #batch of 100\n",
    "            #image = image.to(device)\n",
    "            #label = label.to(device)\n",
    "            pred = model(image)\n",
    "\n",
    "            predSig = mapImageTensor(pred, center= c, scale= s)\n",
    "\n",
    "            for j in range(predSig.size(0)): #split each batch to single frames\n",
    "                frameImage = predSig[j, :, :, :]\n",
    "                frameLabel = label[j, :, :, :]\n",
    "\n",
    "                for t in thresholds:\n",
    "                        predThresh = torch.where(frameImage <= t, 0, 255)\n",
    "                        \n",
    "                        \n",
    "                        TP, FP, TN, FN = metrics(predThresh, frameLabel)\n",
    "\n",
    "                        diceCoeffPerFrame = dice(TP, FP, FN)\n",
    "\n",
    "                        diceByThreshold[str(t)][j] += diceCoeffPerFrame\n",
    "\n",
    "                        for k, metric in enumerate([TP, FP, TN, FN]):\n",
    "                             metricsByThreshold[str(t)][j][k] += metric\n",
    "\n",
    "\n",
    "                        #caseByThreshold[str(t)][str(i+1)].append([predThresh.cpu().detach(), frameLabel.cpu().detach()])\n",
    "\n",
    "                        #oldTP, oldFP, oldTN, oldFN = metricsByThreshold[str(t)][j]\n",
    "                        #newTP = oldTP + TP\n",
    "                        #newFP = oldFP + FP\n",
    "                        #newTN = oldTN + TN\n",
    "                        #newFN = oldFN + FN\n",
    "                        #metricsByThreshold[str(t)][j] = (newTP, newFP, newTN, newFN)\n",
    "\n",
    "                            \n",
    "\n",
    "        for t in thresholds:\n",
    "            diceByThreshold[str(t)] = [val * .25 for val in diceByThreshold[str(t)]]\n",
    "            #metricsByThreshold[str(t)] = [[val * .25 for val in metricByFrame] for metricByFrame in metricsByThreshold[str(t)]]\n",
    "\n",
    "                      \n",
    "        metricResultsByScaleCenter[f'{s}, {c}'] = metricsByThreshold\n",
    "        diceResultsByScaleCenter[f'{s}, {c}'] = diceByThreshold\n",
    "        #predLabelResultsByScaleCenter[f'{s}, {c}'] = caseByThreshold\n",
    "\n",
    "    allDiceResults[modelPath] = diceResultsByScaleCenter\n",
    "    allMetricResults[modelPath] = metricResultsByScaleCenter\n",
    "    #allFrameResults[modelPath] = predLabelResultsByScaleCenter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentTime = datetime.now()\n",
    "formatTime = currentTime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "parentResultsPath = r\"\"\n",
    "diceSavePath = f'{parentResultsPath}\\\\allDiceResults_{formatTime}.txt'\n",
    "metricSavePath = f'{parentResultsPath}\\\\allMetricResults_{formatTime}.txt'\n",
    "#frameSavePath = f'{parentResultsPath}\\\\allFrameResults_{formatTime}.txt'\n",
    "\n",
    "with open(diceSavePath, 'w') as saveFile:\n",
    "    saveFile.write(json.dumps(allDiceResults))\n",
    "\n",
    "\"\"\"\n",
    "edit = {path : {} for path in topModelPaths}\n",
    "\n",
    "for modelPath in topModelPaths:\n",
    "    edit1 = {f'{s}, {c}': {} for s, c in scaleCentersProduct}\n",
    "    for s,c in scaleCentersProduct:\n",
    "        edit2 = {str(t): []*100 for t in thresholds}\n",
    "        for t in thresholds:\n",
    "            listOfLists = allMetricResults[modelPath][f'{s}, {c}'][f'{t}']\n",
    "            for l in listOfLists:\n",
    "                change = list(map(int, l))\n",
    "                edit2[f'{t}'].append(change)\n",
    "        edit1[f'{s}, {c}'] = edit2\n",
    "    edit[modelPath] = edit1\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "with open(metricSavePath, 'w') as saveFile:\n",
    "    saveFile.write(json.dumps(allMetricResults))\n",
    "\n",
    "#torch.save(allFrameResults, frameSavePath)\n",
    "\n",
    "\n",
    "#topAreas = [(0,0,0,0)]* len(scales) * len(thresholds)\n",
    "topAreas = []\n",
    "frameData = [n for n in range(1, 101)]\n",
    "\n",
    "for modelPath in topModelPaths:\n",
    "    for s, c in scaleCentersProduct:\n",
    "        for t in thresholds:\n",
    "            diceList = allDiceResults[modelPath][f'{s}, {c}'][str(t)]\n",
    "            area = rectTriArea(frameData, diceList)\n",
    "            \n",
    "            topAreas.append((modelPath, s, c, t, area))\n",
    "\n",
    "topAreas = sorted(topAreas, key= lambda x : x[4], reverse= True)\n",
    "\n",
    "allModelNames = \"\"\n",
    "for modelName in topModelPaths:\n",
    "    allModelNames = allModelNames + modelName +'\\n'\n",
    "\n",
    "areasResult = {str(i): [] for i in range(len(topAreas)+1)}\n",
    "areasResult['0'].append(f'''Search results for: \\n \n",
    "                    {allModelNames} \n",
    "                    {len(scales)} Scales from [{scales[0]} {scales[-1]}\\n \n",
    "                    {len(centers)} Centers from [{centers[0]} {centers[-1]}\\n \n",
    "                    {len(thresholds)} Thresholds from [{thresholds[0]} {thresholds[-1]}\\n \n",
    "                    ''')\n",
    "\n",
    "for i in range(len(topAreas)):\n",
    "    areasResult[f'{i+1}'] = topAreas[i]\n",
    "\n",
    "currentTime = datetime.now()\n",
    "formatTime = currentTime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "areaParamPath = f'{parentResultsPath}\\Area_and_Params_{formatTime}.txt'\n",
    "\n",
    "with open(areaParamPath, 'w') as saveFile:\n",
    "    saveFile.write(json.dumps(areasResult))\n",
    "    \n",
    "#with open(areaParamPath, 'w') as saveFile:\n",
    "#    allModelNames = \"\"\n",
    "#    for modelName in topModelPaths:\n",
    "#        allModelNames = allModelNames + modelName +'\\n'\n",
    "#    infoString = f'''Search results for: \\n \n",
    "#                    {allModelNames} \n",
    "#                    {len(scales)} Scales from [{scales[0]} {scales[-1]}\\n \n",
    "#                    {len(centers)} Centers from [{centers[0]} {centers[-1]}\\n \n",
    "#                    {len(thresholds)} Thresholds from [{thresholds[0]} {thresholds[-1]}\\n \n",
    "#                    '''\n",
    "#    saveFile.write(infoString)\n",
    "#    for tup in topAreas:\n",
    "#        saveFile.write(str(tup) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    topAreas = globals()[topAreas]\n",
    "    topAreas = topAreas[10:]\n",
    "    print('Loading Top Areas from local variable...')\n",
    "except:\n",
    "    areasResultFilePath = r'' #your path here\n",
    "    print('Loading Top Areas from file path...')\n",
    "    with open(areasResultFilePath, 'r') as file:\n",
    "        areasResult = json.load(file)\n",
    "    topAreas = []\n",
    "    for i in range(1,len(areasResult)):\n",
    "        topAreas.append(areasResult[str(i)])\n",
    "\n",
    "try:\n",
    "    allDiceResults = globals()[allDiceResults]\n",
    "    print('Loading All Dice Results from local variable...')\n",
    "except:\n",
    "    allDiceFilePath = r'' #your path here\n",
    "    print('Loading All Dice Results from file path...')\n",
    "    with open(allDiceFilePath, 'r') as file:\n",
    "        allDiceResults = json.load(file)  \n",
    "\n",
    "try:\n",
    "    allMetricResults = globals()[allMetricResults]\n",
    "    print('Loading All Metrics Results from local variable...')\n",
    "except:\n",
    "    allMetricsFilePath = r'' #your path here\n",
    "    print('Loading All Metrics Results from file path...')\n",
    "    with open(allMetricsFilePath, 'r') as file:\n",
    "        allMetricResults = json.load(file)  \n",
    "\n",
    "\"\"\"\"\n",
    "if allFrameResults:\n",
    "    print('Loading All Frame Results from local variable...')\n",
    "else:\n",
    "    allFrameFilePath = '' #your path here\n",
    "    print('Loading All Frame Results from file path...')\n",
    "    allFrameResults = torch.load(allFrameFilePath)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xCoords = [n for n in range(1, 101)]\n",
    "n = 5\n",
    "currentTime = datetime.now()\n",
    "formatTime = currentTime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "topNResultPath = f'{parentResultsPath}\\\\Top_{n}_Dice_Graph{formatTime}.png'\n",
    "top1ResultPath = f'{parentResultsPath}\\\\Top_1_Dice_Graph{formatTime}.png'\n",
    "\n",
    "for i in range(n):\n",
    "    modelPath = topAreas[i][0]\n",
    "    modelScale = topAreas[i][1]\n",
    "    modelCenter = topAreas[i][2]\n",
    "    modelThresh = topAreas[i][3]\n",
    "    parts = modelPath.split(\"\\\\\")\n",
    "    modelName = parts[3]\n",
    "    yCoords = allDiceResults[modelPath][f'{modelScale}, {modelCenter}'][str(modelThresh)]\n",
    "    plt.plot(xCoords, yCoords, label = f'{modelName} | S: {modelScale} | C: {modelCenter} | T: {modelThresh}')\n",
    "\n",
    "plt.title(f\"Top {n} Results by Model Params\")\n",
    "plt.legend(fontsize = 'small', loc = 'upper left', bbox_to_anchor=(1,1))\n",
    "plt.savefig(topNResultPath)\n",
    "plt.show()\n",
    "\n",
    "xCoords = [n for n in range(1, 101)]\n",
    "n = 1\n",
    "\n",
    "for i in range(n):\n",
    "    modelPath = topAreas[i][0]\n",
    "    modelScale = topAreas[i][1]\n",
    "    modelCenter = topAreas[i][2]\n",
    "    modelThresh = topAreas[i][3]\n",
    "    parts = modelPath.split(\"\\\\\")\n",
    "    modelName = parts[3]\n",
    "    yCoords = allDiceResults[modelPath][f'{modelScale}, {modelCenter}'][str(modelThresh)]\n",
    "    plt.plot(xCoords, yCoords, label = f'{modelName} | S: {modelScale} | C: {modelCenter} | T: {modelThresh}')\n",
    "\n",
    "plt.title(f\"Top Result by Model Params\")\n",
    "plt.legend(fontsize = 'small', loc = 'upper left', bbox_to_anchor=(1,1))\n",
    "plt.savefig(top1ResultPath)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topModelParams = []\n",
    "\n",
    "topModelNum = 1\n",
    "\n",
    "#downscale = torchvision.transforms.Compose([\n",
    "#    torchvision.transforms.Resize((16, 64))])\n",
    "\n",
    "testImagePath = r\"\"\n",
    "testLabelPath = r\"\"\n",
    "\n",
    "logModelFitLoader= image_processor.imageDirsToTestLoader(imageDir=testImagePath, labelDir= testLabelPath)\n",
    "\n",
    "for i in range(topModelNum):\n",
    "    topModelParams.append([topAreas[i][0], topAreas[i][1], topAreas[i][2], topAreas[i][3]])\n",
    "\n",
    "segmentationPath = f\"{parentResultsPath}\\Segmentations\"\n",
    "\n",
    "if not os.path.exists(segmentationPath):\n",
    "    os.makedirs(segmentationPath)\n",
    "\n",
    "\n",
    "for modelName, s, c, t in topModelParams:\n",
    "    currentTime = datetime.now()\n",
    "    formatTime = currentTime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f'START: {modelName} | {formatTime}')\n",
    "    model = unet.unet()\n",
    "    model.load_state_dict(torch.load(modelName))\n",
    "    #model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for case, (image, label) in enumerate(logModelFitLoader):\n",
    "        #image = image.to(device)\n",
    "        #label = label.to(device)\n",
    "        \n",
    "        pred = model(image)\n",
    "\n",
    "        predSig = mapImageTensor(pred, center= c, scale= s)\n",
    "        \n",
    "        for frame in range(predSig.size(0)): #split each batch to single frames\n",
    "            frameImage = predSig[frame, :, :, :]\n",
    "            frameLabel = label[frame, :, :, :]\n",
    "            predThresh = torch.where(frameImage <= t, 0, 255)\n",
    "\n",
    "            framePlotter(predThresh, frameLabel, frame+1, case+1, modelName, segmentationPath)\n",
    "    \n",
    "\n",
    "    #for s, c in scaleCentersProduct:\n",
    "    #    currentTime = datetime.now()\n",
    "    #    formatTime = currentTime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    #    print(f'SCALE: {s} - CENTER: {c} | {formatTime}')\n",
    "        \n",
    "\n",
    "        #for case in range(len(allFrameResults[modelPath][f'{s}, {c}'][f'{t}'])): #for every case\n",
    "        #    for frame, (predMask, label) in enumerate(allFrameResults[modelPath][f'{s}, {c}'][f'{t}'][f'{case+1}']): #for every frame\n",
    "        #        framePlotter(predMask, label, frame+1, case+1, modelPath, segmentationPath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
